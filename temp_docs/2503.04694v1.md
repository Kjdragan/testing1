## Rapid updating of multivariate resource models based on new information using EnKF-MDA and multi-Gaussian transformation

### Sultan Abulkhair[1,2*], Peter A. Dowd[1,2] and Chaoshui Xu[2]


1ARC Training Centre for Integrated Operations for Complex Resources, The
University of Adelaide, Adelaide, SA 5005, Australia.
2School of Chemical Engineering, The University of Adelaide, Adelaide, SA
5005, Australia.
*Corresponding author: sultan.abulkhair@adelaide.edu.au

**Abstract**


Rapid resource model updating with real-time data is important for
making timely decisions in resource management and mining operations. This requires optimal merging of models and observations, which
can be achieved through data assimilation, and the ensemble Kalman
filter (EnKF) has become a popular method for this task. However,
the modelled resources in mining usually consist of multiple variables of interest with multivariate relationships of varying complexity.
EnKF is not a multivariate approach, and even for univariate cases,
there may be slight deviations between its outcomes and observations.
This study presents a methodology for rapidly updating multivariate resource models using the EnKF with multiple data assimilations
(EnKF-MDA) combined with rotation based iterative Gaussianisation
(RBIG). EnKF-MDA improves the updating by assimilating the same
data multiple times with an inflated measurement error, while RBIG
quickly transforms the data into multi-Gaussian factors. The application of the proposed algorithm is validated by a real case study with
nine cross-correlated variables. The combination of EnKF-MDA and
RBIG successfully improves the accuracy of resource model updates,
minimises uncertainty, and preserves the multivariate relationships.

**Keywords: Ensemble Kalman filter with multiple data assimilations;**
Rotation based iterative Gaussianisation; Geostatistics; Senseor observations;
Reconciliation


-----

## 1 Introduction

Resource modelling is a crucial component of the mining value chain, as it
outlines the quantity, quality, and location of mineral resources within a specified area. However, resource models are typically based on limited exploration
data collected over a large area, often failing to accurately represent reality.
As these models are the foundation for future planning, predictions, and optimisations, their accuracy directly impacts production outcomes. To address
potential discrepancies, it is essential to evaluate risks by quantifying the uncertainty associated with the orebody using advanced geostatistical simulation
algorithms (Dowd, 1994). Additionally, collecting more direct measurements
during operations can enhance the accuracy and precision of these models.
Real-time production data from various sensors can quickly update resource
knowledge and inform short-term mine planning decisions. Sensor data provides indirect measurements, known as soft data, which can vary in certainty.
Incorporating these observations into geostatistical models can enhance the
accuracy and precision of forecasts. Buxton and Benndorf (2013) suggest that
integrating sensor data could reduce uncertainty and deviations from production targets, potentially resulting in an average economic benefit of $5 million
per year for the studied deposit.
To effectively integrate sensor observations, tools such as the Kalman filter (KF) (Kalman, 1960) and the ensemble Kalman filter (EnKF) (Evensen,
1994) are recommended for the rapid updating of resource and grade control
models (Benndorf, 2015; Wambeke and Benndorf, 2017). In addition, Benndorf
and Buxton (2016) introduced a real-time mining concept that transforms
discontinuous process monitoring into a near-continuous framework through
data assimilation (see Figure 1). Data assimilation applications extend beyond
mineral grade estimates and can also be used to update coal quality parameters (Y¨uksel et al, 2016), geometallurgical models (Wambeke et al, 2018),
and compositional data (Prior et al, 2021b). However, current data assimilation methods for quickly updating resource models still have limitations. For
instance, the EnKF updates one variable at a time and does not consider multivariate relationships. Furthermore, single data assimilation is often insufficient
to fully utilise the information obtained from observations.
One practical approach for performing multivariate rapid updating is
to transform co-regionalised variables into independent factors before data
assimilation. This transformation helps preserve multivariate relationships by
back-transforming realisations after updates. Techniques such as the minimummaximum autocorrelation factors (MAF) (Desbarats and Dimitrakopoulos,
2000) and flow transformation (FT) (van den Boogaart et al, 2017) have been
used alongside the EnKF to decorrelate multivariate data before rapid updating (Kumar et al, 2020; Prior et al, 2021b). However, MAF is not well-suited
for handling complex multivariate relationships, and FT tends to be too slow
for adequate rapid updating. In a comparison of various multivariate transformations, Abulkhair et al (2023) found that the projection pursuit multivariate


-----

**Figure 1. Real-time mining concept inspired by Benndorf and Buxton (2016).**

transform (PPMT) (Barnett et al, 2014) and rotation-based iterative Gaussianisation (RBIG) (Laparra et al, 2011) are considerably faster and more
appropriate for rapid updating than FT.
In addition to the EnKF, several other methods have been employed
for the rapid updating of resource models, including conditional simulation
of successive residuals (Vargas-Guzm´an and Dimitrakopoulos, 2002), direct
sequential simulation using point distributions (Neves et al, 2019), a variation of the KF for downscaling resource models (Li et al, 2021), and deep
reinforcement learning (Kumar and Dimitrakopoulos, 2022). Most of these
methods perform single data assimilation, which can lead to some deviations
between predicted and observed values, especially when observations are highly
uncertain. To improve data assimilation in highly non-linear situations, iterative forms of EnKF have been widely explored in petroleum engineering and
hydrogeology. For instance, ensemble randomised maximum likelihood, also
known as iterative EnKF (Chen and Oliver, 2012; Gu and Oliver, 2007), yields
better-matching results than standard EnKF, although it requires more computational resources. Alternatively, EnKF with multiple data assimilations
(EnKF-MDA) (Emerick and Reynolds, 2012, 2013) performs multiple data
assimilations with an inflated measurement error to significantly outperform
single data assimilation methods. While both iterative EnKF and EnKF-MDA
are more computationally intensive than standard EnKF, the EnKF-MDA
approach typically requires fewer iterations.
Validating the performance of data assimilation algorithms through real
case studies is crucial, especially in the mining industry, where data often show
significant variability in terms of spacing between data points, measurement
volumes, and associated uncertainties. Several studies of rapid resource model
updating have demonstrated the effectiveness of various proposed approaches
when applied to real data (Kumar et al, 2020; Prior et al, 2021a,b; Wambeke
et al, 2018; Y¨uksel et al, 2017). In this paper, we apply a combination of EnKFMDA and RBIG to a real anonymised mining dataset provided by Petra Data


-----

Science. The following section offers a detailed methodology for the proposed
rapid updating algorithm. Next, real fused data is used to sequentially update
the resource model over 25 time periods, the results of which are thoroughly
analysed. The paper then concludes with a discussion of key results, limitations
of the proposed algorithm, and future research directions.

## 2 Methods

### 2.1 Rapid updating of multivariate resource models

The proposed updating approach uses EnKF-MDA (Emerick and Reynolds,
2012, 2013) for data assimilation, paired with RBIG (Laparra et al, 2011) for
decorrelation and Gaussianisation of cross-correlated variables. The steps in
the proposed algorithm are as follows:

1. Select a neighbourhood around the observations and extract block model
realisations located within that neighbourhood. In this paper, the neighbourhood is determined by the pre-defined number of blocks from each
observation.
2. Transform neighbourhood realisations and new observations into multiGaussian factors using RBIG

_Ge = ΦRBIG (Ve),_ (1)

where Ve is a vector combining n neighbourhood realisations Ze[n,t] and
observations Oe[t] [with the number of variables][ e][ at a time][ t][,][ G][e] [is a trans-]
RBIG
formed vector later divided into multi-Gaussian realisations Ze[n,t] and
RBIG
observations Oe[t] .
RBIG
3. Apply EnKF-MDA to get updated multi-Gaussian realisations Ze[n,t][+1]

based on prior realisations and observations

RBIG � RBIG _t_ RBIG[�]
_Ze[n,t][+1]_ = ΦEnKF-MDA _Ze[n,t]_ _, Oe_ _._ (2)

4. Back-transform updated realisations into the original state

� RBIG[�]
_Ze[n,t][+1]_ = Φ[−]RBIG[1] _Ze[n,t][+1]_ _,_ (3)

where Φ[−]RBIG[1] [is an inverse RBIG transformation and][ Z]e[n,t][+1] are backtransformed updated neighbourhood realisations.
5. Insert the updated neighbourhood realisations back into the block model.

### 2.2 Rotation based iterative Gaussianisation

RBIG is an iterative multi-Gaussian transform based on marginal Gaussianisation followed by orthonormal PCA rotation (Laparra et al, 2011). RBIG is


-----

chosen as the optimal multi-Gaussian transform for rapid updating because it
is significantly faster than other methods while maintaining comparable performance across various categories (Abulkhair et al, 2023). In a similar study,
RBIG demonstrated an approximate 90% reduction in run time compared to
PPMT (Cook et al, 2023).
A single iteration of RBIG is defined as

_Ye[i][+1]_ = R[i]Ψ[i][ �]Xe[i]� _,_ (4)

where Ψ[i][ �]Xe[i]� is a marginal Gaussianisation based on histogram equalisation
of the multivariate data at iteration i and R[i] is a PCA rotation matrix.
Marginal Gaussianisation functions and rotation matrices at each iteration
are stored as ΦRBIG. The back-transformation Φ[−]RBIG[1] [is performed by following]
the stored iterations in reverse order.

### 2.3 Ensemble Kalman filter with multiple data assimilations

EnKF-MDA is an iterative version of EnKF as it performs multiple data
assimilations on the same data with an inflated measurement error (Emerick
and Reynolds, 2012). It provided a significantly better match between predictions and observations compared to single data assimilation methods while
not being overly computationally intensive (Emerick and Reynolds, 2013). The
steps of the EnKF-MDA implemented for rapid resource model updating are
the following:

1. Compute model-based predictions He[n,t] at observation locations.
2. Add random noise to observations according to the measurement error

_Oe[t]_ [=][ O]e[t] [+][ ε.] (5)

3. Compute the Gaspari-Cohn correlation filter for covariance localisation


_α(r) =_


− 4[1] _[r][5][ +]_ [1]2 _[r][4][ +]_ [5]8 _[r][3][ −]_ [5]2 _[r][2][ + 1]_ 0 ≤ _r < 1_
 121 _[r][5][ −]_ 2[1] _[r][4][ +]_ [5]8 _[r][3][ +]_ 3[5] _[r][2][ −]_ [5][r][ + 4][ −] [2]3 _[r][−][1]_ 1 < r ≤ 2 _,_ (6)

0 _r > 2_


where r is a normalised distance between two locations defined by _L[d]_ [,][ d][ is]

a distance and L is a predefined localisation radius.
4. Compute the Kalman gain

_Ke[t]_ [=][ α][(][r][)][C]Y D[e,t] �α(r)CDD[e,t] [+][ C]D[e,t]� _,_ (7)

where CY D[e,t] [is the experimental covariance between realisations and model-]
based predictions, CDD[e,t] [is the experimental covariance of model-based]
predictions and CD[e,t] [is the experimental covariance of observations.]


-----

5. Update prior realisations

_Ze[n,t][+1]RBIG = Zen,tRBIG + Ket_ �Oe[t] RBIG − _Hen,t�_ _._ (8)

6. Repeat steps 1-4 for a predefined number of data assimilations and
ensure that random noise added to observations differs from previous data
assimilations.

## 3 Results

### 3.1 Overview of a case study

In this case study, the proposed approach is applied to real data provided by
Petra Data Science. The dataset, which has been anonymised, was fused using
the company’s Maxta software to track the collected data points back to their
respective resource blocks. For more details about data fusion and orebody
learning in the MAXTA software, readers can refer to the paper by Petra Data
Science (Stewart et al, 2022). Due to confidentiality reasons, we cannot disclose
the name of the deposit, the variable names, or the coordinates. Figure 2
provides a 3D view of the study area, specifically highlighting a prior resource
model and observations that will be used to update the model. There are nine
cross-correlated assay variables, and 18,295 observations are categorised into
25 periods based on the months in which they were collected. For the sake of
simplicity, the measurement error is assumed to be a constant value of 10%.

**Figure 2. 3D view of a prior resource model with average values of Assay 1 (left) and**
observations divided into 25 periods (right).

The resource model consists of 100 realisations with blocks of size 10 m
× 10 m × 4 m. Figure 3 provides a 2D view of the e-type models for each
assay variable at an elevation of 44 m. As the observations were tracked back
to their corresponding blocks, the spacing between the data points aligns with
the dimensions of the blocks.


-----

**Figure 3. 2D view of prior resource models at 44 m elevation.**

### 3.2 An illustrative example of rapid updating for period 1

As outlined in the methodology of the proposed updating algorithm, observations are not used to update the entire block model. For one reason, updating
blocks that are far from the observations would unnecessarily reduce the uncertainty of those blocks. More importantly, calculating covariance matrices for
the entire model is both time-consuming and inefficient in terms of memory
usage. Therefore, the first step of the updating algorithm is to select the neighbourhood around the observations. In this study, the neighbourhood is defined
as being within three blocks away from observation points. For example, for
period 1, with 868 observations, the neighbourhood consists of 15,561 blocks.
The next step involves transforming neighbourhood realisations and observations into multi-Gaussian factors. If the prior model was created using RBIG,
one possible strategy would be to use stored RBIG functions and matrices from
the prior model. However, this could make the proposed algorithm inflexible
and overly dependent on the original exploration data. The transformation step
of the proposed algorithm must be capable of transforming any prior model
realisations, not just those created using RBIG. Additionally, new observations
should be taken into account during the transformation, as they may exhibit
slightly different distributions.
To address this issue, the proposed algorithm simultaneously applies RBIG
to both the prior neighbourhood realisations and the observations (see Eq. 1).
A potential drawback, however, is that it will take more time to transform a
vector combining observations and blocks from all realisations. Nevertheless,
previous studies of the application of RBIG in geostatistics indicated that it
is much faster than other methods, such as PPMT (Abulkhair et al, 2023;
Cook et al, 2023). In this case, it took 70 seconds to transform a 9-dimensional


-----

vector combining 100 realisations of 15,561 blocks and 868 observations, giving
a total of 1,556,968 rows.
Cross-plots of original and transformed variables are shown in Figure 4.
The multivariate relationships in this dataset are complex, with non-linearities
in some bivariate distributions. There is also a noticeable skewness in some
variables, particularly Assay 3. The cross plots of both prior realisation and
observations are visually similar in terms of kernel density and ranges. Ultimately, RBIG successfully generated multi-Gaussian factors that satisfy the
Gaussian assumption of EnKF-MDA.

**Figure 4. Cross-plots of assay variables and corresponding RBIG factors for observations**
in period 1 and a prior realisation of the neighbourhood around the observations.

Multi-Gaussian realisations and observations are used as inputs for EnKFMDA to perform rapid updating. The critical decision at this stage is to choose
the number of data assimilations, as this choice impacts both performance and
computation time. Typically, the run time of EnKF-MDA is equal to the run
time of EnKF multiplied by the number of data assimilations. However, it is
important to note that while accuracy improves with each data assimilation,
the rate of improvement decreases with each subsequent assimilation. Table 1
shows the mean squared error (MSE) reduction results for all variables updated
with a number of data assimilations ranging from 1 to 10. MSE reduction is
defined as

MSE ↓= [MSE][before][ −] [MSE][after] _× 100%,_ (9)

MSEbefore

where MSEbefore is an error between prior predictions and observations and
MSEafter is an error between updated predictions and observations.
A standard EnKF helps reduce MSE by 61-77% across nine assay variables.
With five data assimilations, the error reduction improves to 84-91%, which


-----

**Table 1. MSE reduction (%) for different numbers of data assimilations in period 1**

Number Assay 1 Assay 2 Assay 3 Assay 4 Assay 5 Assay 6 Assay 7 Assay 8 Assay 9

1 66.12 66.30 71.78 60.89 63.26 63.07 68.45 62.80 76.56
2 76.11 76.20 80.37 72.31 74.13 73.98 77.87 73.92 83.80
3 81.05 80.87 84.19 77.88 79.75 79.45 82.36 80.84 86.96
4 84.35 84.27 87.12 81.75 83.21 83.02 85.49 83.34 89.42
5 86.61 86.61 89.12 84.41 85.59 85.48 87.64 85.61 91.09
6 88.19 88.16 90.37 86.24 87.35 87.22 89.09 87.47 92.10
7 89.45 89.43 91.42 87.71 88.71 88.59 90.27 88.82 92.98
8 90.50 90.55 92.39 88.97 89.78 89.72 91.28 89.77 93.79
9 91.33 91.40 93.10 89.94 90.65 90.61 92.06 90.61 94.38
10 92.01 92.11 93.69 90.76 91.36 91.34 92.71 91.28 94.87

provides a good balance between accuracy and computation time. Finally,
after ten data assimilations, all nine variables achieved an MSE reduction of
over 90%. Each data assimilation, which involved 100 realisations with 15,561
blocks and 868 observations, took 1.7 seconds to complete. This means that
ten data assimilations took just 153 seconds in total. Given the relatively fast
computation speed, we have set the number of data assimilations in this case
to ten. Additionally, the covariance localisation radius was chosen to be 30 m.
Predictions versus observations plots indicate that the updated multiGaussian results closely align with the diagonal line (Figure 5). After backtransformation, all variables, except for Assay 2 and Assay 8, maintained an
error reduction close to 90%. The lower error reductions for these two variables
can be attributed to the skewness of their distributions, which impacted the
back-transformation process. Notably, although Assay 3 is also highly skewed,
its prior prediction is much closer to the diagonal line compared to Assay 2
and Assay 8. The long tails of the predicted values for Assay 2 and Assay 8
contain numerous highly inaccurate predictions, ultimately impacting the final
updated results.

**Figure 5. Predictions versus observations plots before and after the update in period 1 in**
multi-Gaussian and back-transformed states.


-----

The proposed approach not only accurately updated most of the variables
but also preserved the multivariate relationships. In Figure 6, cross-plots of
RBIG factors and back-transformed assay variables for the updated realisation
show distributions identical to those in Figure 4. Additionally, the backtransformation of all updated neighbourhood realisations was completed in just
55 seconds. This is a major advantage of combining EnKF-MDA with RBIG,
as many traditional methods struggle to maintain these complex relationships
or lack computational efficiency.

**Figure 6. Cross-plots of assay variables and corresponding RBIG factors for an updated**
realisation in period 1.

All data assimilation and multi-Gaussian transformations were carried out
on a Mac Mini (Apple M4 chip with four performance cores, six efficiency
cores, and 16 GB of RAM). The data assimilation was implemented in Python,
with covariances calculated using Cython. The multi-Gaussian transformation
and back-transformation were performed in MATLAB. Overall, updating the
model in period 1 took 278 seconds: 70 seconds for the RBIG transformation,
153 seconds for the EnKF-MDA, and 55 seconds for the back-transformation.
This efficiency makes the proposed algorithm suitable for near real-time applications in mining, where accurate and up-to-date resource models are essential
for rapid decision-making.


-----

### 3.3 Sequential rapid updating for the remaining periods

To evaluate the effectiveness of the proposed rapid updating algorithm over
time, the resource model realisations were updated sequentially using observations from 25 time periods. The following figures illustrate how the model
is progressively refined as more observations become available. Instead of presenting the updates for each individual period, the updates are grouped into
approximately equal batches of observations, focusing on a 2D section of the
model at an elevation of 44 m.
The prior models, shown in Figure 3, exhibit a smoothing effect that is common in geostatistical modelling. Figure 7 shows the observations from periods
1 to 5 at an elevation of 44 m. In contrast to prior maps, these observations
are evidently different at the exact locations and exhibit greater spatial variability. This emphasises why rapid updating is important, as resource models
often struggle to capture small-scale variability due to the limited resolution of
exploration data. Although sensor observations come with a degree of uncertainty, they offer a vast amount of real-time data that can be integrated into
the model.

**Figure 7. 2D view of observations from periods 1-5 at 44 m elevation.**

After updating the model sequentially over the first five periods, the
updated e-type models are shown in Figure 8. Firstly, the updated models
align more closely with the observations and demonstrate greater variability in that part of the deposit. The rapid updating also increased the spatial
variability and reduced the over-smoothing in the area surrounding the observations. However, there is a region between 600-800 m northing and 1100-1300


-----

**Figure 8. 2D view of updated resource models after period 5 at 44 m elevation.**

m easting that differs significantly from the prior models despite lacking observations there. This is likely the result of neighbouring observations at adjacent
elevations affecting this area.

**Figure 9. 2D view of observations from periods 6-9 at 44 m elevation.**

Figure 9 illustrates four more sets of observations from periods 6 to 9.
The first thing to notice here is that the area between 600-800 m northing
and 1100-1300 m easting, which was unexpectedly updated in Figure 8, aligns


-----

closely with actual observations at those locations. This indicates that nearby
data can contribute to refining the model predictions. However, the biggest
discrepancies between new observations and previous models are found in the
lower sections of the maps. Updated models after period 9 now provide a more
accurate representation of that lower part of the map (Figure 10). Furthermore,
previously underestimated high-grade zones have also become more distinct
for variables such as Assay 4 and Assay 7.

**Figure 10. 2D view of updated resource models after period 9 at 44 m elevation.**

Finally, the observations from the remaining periods are presented in
Figure 11. The reason for displaying such a large set of periods is that most
observations from this batch are not present at an elevation of 44 m. The final
updated models demonstrate greater spatial variability and a higher level of
detail compared to the prior models, particularly in areas with dense observation coverage (Figure 12). Visually, there is a clear and gradual improvement
throughout the updates, as seen in Figures 8 and 10.
A more detailed analysis of the final updated models is presented in
Figure 13, where predictions are plotted against the observed values. The
updated results closely align with the diagonal line, and most variables achieve
an error reduction between 86% and 97%. However, Assay 8 only reduced
its MSE by 76.73%, which is significantly lower compared to the other variables. This discrepancy is particularly evident in the plot, with many points
positioned far from the diagonal line.
A similar trend was noted in Figure 5, where, for period 1, Assay 8 achieved
an error reduction of less than 70%. As mentioned earlier, this issue can be
partly attributed to the skewness of the distribution, which makes it challenging to accurately back-transform the tail end. Another possible reason for this


-----

**Figure 11. 2D view of observations from periods 10-25 at 44 m elevation.**

**Figure 12. 2D view of final updated resource models at 44 m elevation.**

underperformance is the relatively high number of prior predictions that were
significantly inaccurate.
Interestingly, Assay 2 showed an improvement in error reduction compared
to period 1, but there are still points that deviate from the diagonal line.
Assay 3 demonstrates even better accuracy despite having a more skewed
distribution. The difference between Assay 8 and Assay 3 is that the latter
has fewer observations at the tail end of its distribution. However, RBIG still


-----

**Figure 13. Predictions vs. observations plots for prior resource models (in red) and after**
the final update in period 25 (in blue).

struggled to back-transform the tails in both cases, raising concerns about
its reliability for highly skewed distributions. Overall, the proposed algorithm
effectively reduced the MSE by 94-98% across five out of nine variables.
All the previous figures primarily analyse the average results from all realisations. To focus on how rapid updating affects individual realisations, we
calculated the errors between the updated results and the observations. In
each period, we selected a block with an error close to the median of all the
errors. We chose the median because it ensures that 50% of the blocks exhibit
better predictions while the other 50% show worse predictions. Figure 14 displays the prior and updated realisations for the blocks that have errors near
the median in each period. The updated results closely match the observations
for each variable. Furthermore, rapid updating has minimised uncertainty, as
evidenced by the reduced spread of realisations before and after the updates.
However, uncertainty is slightly higher for larger values due to the skewness
of the distributions. This is particularly evident in Assay 6, where values in
later periods are significantly higher and have a broader spread of realisations.
Interestingly, Assay 8, despite showing relatively low error reduction, shows
very accurate results in this figure.
The proposed approach, as shown in the predictions versus observations
plots in Figure 13, produces some outliers that are far from the diagonal line.
This issue is particularly evident in Assays 2 and 8, which demonstrate lower
error reductions than the other variables. To illustrate this, Figure 15 shows
the realisations before and after rapid updating for the blocks with the highest errors during each period. Variables that had good error reductions remain


-----

**Figure 14. Visualisation of realisations before and after rapid updating for blocks with**
errors close to the median in each period.

**Figure 15. Visualisation of realisations before and after rapid updating for blocks with**
highest errors in each period.

close to the observed values. For instance, in Assay 4, the slight deviation
from the observations is primarily due to overestimation in prior models. In
contrast, Assay 6 shows that prior models have both overestimation and underestimation in different periods, leading to deviations from observations in the
updated models. For Assays 2 and 8, however, the gap between realisations and
observations is more significant, primarily due to back-transformation issues.


-----

## 4 Conclusions

This paper presents a rapid updating algorithm designed explicitly for multivariate resource models. The algorithm combines EnKF-MDA and RBIG,
where the former offers more accurate updates compared to the traditional
EnKF, while RBIG transforms multivariate data into independent multiGaussian factors that are suitable for updating. This approach is applicable to
any mining deposit that has multiple cross-correlated quantitative variables.
The effectiveness of the proposed algorithm was demonstrated using real fused
data provided by Petra Data Science, achieving an error reduction ranging
from 77% to 98% across nine cross-correlated variables. EnKF-MDA enhances
the prediction accuracy with five variables, reducing their errors by more than
90%. RBIG satisfies the Gaussian assumption of EnKF-MDA and maintains
multivariate relationships.
In addition to the accuracy, the proposed algorithm operates with impressive speed, even on low-cost hardware. For instance, it can update 100 block
model realisations with nearly 900 observations from period 1 in under five
minutes. The process could be further enhanced through parallelisation across
multiple virtual machines, which is easily achievable in an industrial setting.
Notably, the rapid updating requires no human intervention and can be automated to run either at specified time intervals or immediately when new
information is available. As a result, mining operations can make near realtime decisions based on updated models, leading to improved short-term mine
planning and optimisation.
However, some challenges need to be addressed in future research regarding rapid resource model updating. The uncertainty associated with soft data,
such as sensor observations, extends beyond measurement errors typically identified in laboratory settings. The way sensors are used on an actual mine
site can differ from how they are intended to be used. Not to mention the
difference between harsh mining conditions and a laboratory environment
where measurement errors are evaluated. Furthermore, although more practical, downstream sensors, such as those on conveyor belts, are hard to link
back to resource models. This challenge is particularly relevant in underground
mining, where ore tracking remains a significant issue for mining companies.
Thus, the uncertainty introduced by ore tracking must be considered during
rapid updating.
Quantitative grade variables are not the only critical components of
resource models. Qualitative variables, such as lithology, alterations and various domain types, are also essential for resource modelling, optimisation,
and mine planning. The primary challenge with qualitative information is
that ensemble-based data assimilation mainly operates on Gaussian values.
One approach to addressing this challenge is to parametrise qualitative variables into quantitative ones. For example, discrete wavelet transforms can
be used to turn geological domains into frequency coefficients before data


-----

assimilation (Talesh Hosseini et al, 2023). Alternatively, domains may be represented as multiple Gaussian random fields through pluri-Gaussian simulation
(Armstrong et al, 2011).
It is also important to rapidly update geometallurgical models as these
parameters can be used to optimise the entire mining value chain. However,
this is challenging due to the limited availability of geometallurgical tests for
accurate predictions, coupled with many geometallurgical parameters that are
non-additive. Nevertheless, applying EnKF to update the Bond Ball Mill Work
index helped reduce prediction errors by 72 % and improved future forecasts
by 26 % (Wambeke et al, 2018). Future research will focus on expanding the
data assimilation algorithm to enable the updating of qualitative variables
(e.g., geological domains) and geometallurgical properties.

**Acknowledgments.** The research reported here was supported by the
Australian Research Council Industrial Transformation Training Centre for
Integrated Operations for Complex Resources (ARC ITTC IOCR - project
number IC190100017) and funded by universities, industry and the Australian
Government. We acknowledge Petra Data Science for providing a fused dataset
for our experiments.

## References

Abulkhair S, Dowd P, Xu C (2023) Geostatistics in the Presence of Multivariate Complexities: Comparison of Multi-Gaussian Transforms. Mathematical
[Geosciences 55:713–734. https://doi.org/10.1007/s11004-023-10056-y](https://doi.org/10.1007/s11004-023-10056-y)
Armstrong M, Galli A, Beucher H, et al (2011) Plurigaussian Simulations in
Geosciences. Springer, Heidelberg
Barnett R, Manchuk J, Deutsch C (2014) Projection Pursuit Multivariate
[Transform. Mathematical Geosciences 46:337–359. https://doi.org/10.1007/](https://doi.org/10.1007/s11004-013-9497-7)
[s11004-013-9497-7](https://doi.org/10.1007/s11004-013-9497-7)
Benndorf J (2015) Making Use of Online Production Data: Sequential Updating of Mineral Resource Models. Mathematical Geosciences 47:547–563.
[https://doi.org/10.1007/s11004-014-9561-y](https://doi.org/10.1007/s11004-014-9561-y)
Benndorf J, Buxton M (2016) Sensor-based real-time resource model reconciliation for improved mine production control – a conceptual framework.
[Mining Technology 125(1):54–64. https://doi.org/10.1080/14749009.2015.](https://doi.org/10.1080/14749009.2015.1107342)
[1107342](https://doi.org/10.1080/14749009.2015.1107342)
Buxton M, Benndorf J (2013) The use of sensor derived data in optimization
along the Mine-Value-Chain. In: Proceedings of the 15th international ISM
congress, Aachen, Germany. SME, p 324–336
Chen Y, Oliver D (2012) Ensemble Randomized Maximum Likelihood Method
as an Iterative Ensemble Smoother. Mathematical Geosciences 44:1–26.
[https://doi.org/10.1007/s11004-011-9376-z](https://doi.org/10.1007/s11004-011-9376-z)
Cook A, Rondon O, Graindorge J, et al (2023) Iterative Gaussianisation for
Multivariate Transformation. In: Avalos S, Ortiz J, Srivastava RM (eds)


-----

[Geostatistics Toronto 2021. Springer, Cham, p 21–35, https://doi.org/10.](https://doi.org/10.1007/978-3-031-19845-8_2)
[1007/978-3-031-19845-8 2](https://doi.org/10.1007/978-3-031-19845-8_2)
Desbarats A, Dimitrakopoulos R (2000) Geostatistical Simulation of Regionalized Pore-Size Distributions Using Min/Max Autocorrelation Factors. Math[ematical Geology 32:919–942. https://doi.org/10.1023/A:1007570402430](https://doi.org/10.1023/A:1007570402430)
Dowd P (1994) Risk assessment in reserve estimation and open-pit planning.
IMM Transactions, Mining Industry 103(A):148–154
Emerick A, Reynolds A (2012) History matching time-lapse seismic data using
the ensemble Kalman filter with multiple data assimilations. Computational
[Geosciences 16:639–659. https://doi.org/10.1007/s10596-012-9275-5](https://doi.org/10.1007/s10596-012-9275-5)
Emerick A, Reynolds A (2013) Ensemble smoother with multiple data assimi[lation. Computers & Geosciences 55:3–15. https://doi.org/10.1016/j.cageo.](https://doi.org/10.1016/j.cageo.2012.03.011)
[2012.03.011](https://doi.org/10.1016/j.cageo.2012.03.011)
Evensen G (1994) Sequential data assimilation with a nonlinear quasigeostrophic model using Monte Carlo methods to forecast error statistics.
[Journal of Geophysical Research 99(C5):10,143–10,162. https://doi.org/10.](https://doi.org/10.1029/94JC00572)
[1029/94JC00572](https://doi.org/10.1029/94JC00572)
Gu Y, Oliver D (2007) An Iterative Ensemble Kalman Filter for Multiphase
[Fluid Flow Data Assimilation. SPE Journal 12(04):438–446. https://doi.](https://doi.org/10.2118/108438-PA)
[org/10.2118/108438-PA](https://doi.org/10.2118/108438-PA)
Kalman R (1960) A New Approach to Linear Filtering and Prediction Prob[lems. Journal of Basic Engineering 82(1):35–45. https://doi.org/10.1115/1.](https://doi.org/10.1115/1.3662552)
[3662552](https://doi.org/10.1115/1.3662552)
Kumar A, Dimitrakopoulos R (2022) Updating geostatistically simulated models of mineral deposits in real-time with incoming new information using
actor-critic reinforcement learning. Computers & Geosciences 158:104,962.
[https://doi.org/10.1016/j.cageo.2021.104962](https://doi.org/10.1016/j.cageo.2021.104962)
Kumar A, Dimitrakopoulos R, Maulen M (2020) Adaptive self-learning mechanisms for updating short-term production decisions in an industrial mining
[complex. Journal of Intelligent Manufacturing 31:1795–1811. https://doi.](https://doi.org/10.1007/s10845-020-01562-5)
[org/10.1007/s10845-020-01562-5](https://doi.org/10.1007/s10845-020-01562-5)
Laparra V, Camps-Valls G, Malo J (2011) Iterative Gaussianization: From ICA
to Random Rotations. IEEE Transactions on Neural Networks 22(4):537–
[549. https://doi.org/10.1109/TNN.2011.2106511](https://doi.org/10.1109/TNN.2011.2106511)
Li Y, Sep´ulveda E, Xu C, et al (2021) A Rapid Updating Method to Predict
Grade Heterogeneity at Smaller Scales. Mathematical Geosciences 53:1237–
[1260. https://doi.org/10.1007/s11004-020-09901-1](https://doi.org/10.1007/s11004-020-09901-1)
Neves J, Pereira M, Pacheco N, et al (2019) Updating Mining Resources with
[Uncertain Data. Mathematical Geosciences 51:905–924. https://doi.org/10.](https://doi.org/10.1007/s11004-018-9759-5)
[1007/s11004-018-9759-5](https://doi.org/10.1007/s11004-018-9759-5)
Prior A, Benndorf J, Mueller U (2021a) Resource and Grade Control Model
Updating for Underground Mining Production Settings. Mathematical
[Geosciences 53:575–779. https://doi.org/10.1007/s11004-020-09881-2](https://doi.org/10.1007/s11004-020-09881-2)


-----

Prior A, Tolosana-Delgado R, van den Boogaart KG, et al (2021b) Resource
Model Updating For Compositional Geometallurgical Variables. Mathemat[ical Geosciences 53:945–968. https://doi.org/10.1007/s11004-020-09874-1](https://doi.org/10.1007/s11004-020-09874-1)
Stewart P, Pokrajcic Z, Hu X, et al (2022) The application of digital twin
machine learning models for Mine to Mill and Pit to Plant optimisation. In:
Open Pit Operators Conference 2022. AusIMM, Perth, p 288–304
Talesh Hosseini S, Asghari O, Benndorf J, et al (2023) Real-time Uncertain
Geological Boundaries Updating for Improved Block Model Quality Control
Based on Blast Hole Data: A Case Study for Golgohar Iron Ore Mine in
[Southeastern Iran. Mathematical Geosciences 55:541–562. https://doi.org/](https://doi.org/10.1007/s11004-022-10030-0)
[10.1007/s11004-022-10030-0](https://doi.org/10.1007/s11004-022-10030-0)
van den Boogaart K, Mueller U, Tolosana-Delgado R (2017) An Affine
Equivariant Multivariate Normal Score Transform for Compositional
Data. Mathematical Geosciences 49:231–251. [https://doi.org/10.1007/](https://doi.org/10.1007/s11004-016-9645-y)
[s11004-016-9645-y](https://doi.org/10.1007/s11004-016-9645-y)
Vargas-Guzm´an J, Dimitrakopoulos R (2002) Conditional Simulation of Random Fields by Successive Residuals. Mathematical Geology 34:597–611.
[https://doi.org/10.1023/A:1016099029432](https://doi.org/10.1023/A:1016099029432)
Wambeke T, Benndorf J (2017) A Simulation-Based Geostatistical Approach
to Real-Time Reconciliation of the Grade Control Model. Mathematical
[Geosciences 49:1–37. https://doi.org/10.1007/s11004-016-9658-6](https://doi.org/10.1007/s11004-016-9658-6)
Wambeke T, Elder D, Miller A, et al (2018) Real-time reconciliation of a
geometallurgical model based on ball mill performance measurements – a
pilot study at the Tropicana gold mine. Mining Technology 127(3):115–130.
[https://doi.org/10.1080/25726668.2018.1436957](https://doi.org/10.1080/25726668.2018.1436957)
Y¨uksel C, Thielemann T, Wambeke T, et al (2016) Real-time resource model
updating for improved coal quality control using online data. International
[Journal of Coal Geology 162:61–73. https://doi.org/10.1016/j.coal.2016.05.](https://doi.org/10.1016/j.coal.2016.05.014)
[014](https://doi.org/10.1016/j.coal.2016.05.014)
Y¨uksel C, Benndorf J, Lindig M, et al (2017) Updating the coal quality
parameters in multiple production benches based on combined material
measurement: a full case study. International Journal of Coal Science &
[Technology 4:159–171. https://doi.org/10.1007/s40789-017-0156-3](https://doi.org/10.1007/s40789-017-0156-3)


-----

